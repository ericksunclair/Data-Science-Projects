{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install --yes tensorflow\n",
    "# !conda install --yes keras\n",
    "# !conda install --yes scikit-learn\n",
    "# !conda install --yes opencv\n",
    "# !conda install --yes pillow\n",
    "# !conda install --yes numpy\n",
    "# !conda install --yes matplotlib\n",
    "# !conda install --yes theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "# import tensorflow_datasets as tfds\n",
    "# tf.enable_eager_execution()\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_path = \"Fast Food Classification V2\\Train\"\n",
    "valid_path = \"Fast Food Classification V2\\Valid\"\n",
    "test_path = \"Fast Food Classification V2\\Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baked Potato',\n",
       " 'Burger',\n",
       " 'Crispy Chicken',\n",
       " 'Donut',\n",
       " 'Fries',\n",
       " 'Hot Dog',\n",
       " 'Pizza',\n",
       " 'Sandwich',\n",
       " 'Taco',\n",
       " 'Taquito']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important informations\n",
    "IMG_SIZE = 256\n",
    "CATEGORIES = sorted(os.listdir(train_path))\n",
    "CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_train and y_train\n",
    "training = []\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(train_path, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        training.append([new_array, class_num])\n",
    "\n",
    "random.shuffle(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [features for features, label in training]\n",
    "y_train = [label for features, label in training]\n",
    "# for features, label in training:\n",
    "#     X_train.append(features)\n",
    "#     y_train.append(label)\n",
    "# reshape for the input format expected by keras (256, 256, 3) - 3 channels\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3).astype('float32')\n",
    "# normalizing the pixel values\n",
    "X_train = X_train / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "(15000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "print(y_train[100])\n",
    "print(shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_valid and y_valid\n",
    "validation = []\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(valid_path, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        validation.append([new_array, class_num])\n",
    "\n",
    "random.shuffle(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = [features for features, label in validation]\n",
    "y_valid = [label for features, label in validation]\n",
    "# for features, label in validation:\n",
    "#     X_valid.append(features)\n",
    "#     y_valid.append(label)\n",
    "# reshape for the input format expected by keras (256, 256, 3) - 3 channels\n",
    "X_valid = np.array(X_valid).reshape(-1, IMG_SIZE, IMG_SIZE, 3).astype('float32')\n",
    "# normalizing the pixel values\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "(3500, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_valid = np_utils.to_categorical(y_valid, 10)\n",
    "print(y_valid[100])\n",
    "print(shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - ETA: 0s - loss: 2.2262 - accuracy: 0.19 - 1646s 2s/step - loss: 2.2262 - accuracy: 0.1933 - val_loss: 2.0736 - val_accuracy: 0.2780\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 1788s 2s/step - loss: 1.8251 - accuracy: 0.3778 - val_loss: 1.8510 - val_accuracy: 0.3809\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 1812s 2s/step - loss: 1.1492 - accuracy: 0.6199 - val_loss: 2.0258 - val_accuracy: 0.4020\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 1779s 2s/step - loss: 0.5297 - accuracy: 0.8294 - val_loss: 2.5481 - val_accuracy: 0.4003\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 1683s 2s/step - loss: 0.2551 - accuracy: 0.9218 - val_loss: 3.8223 - val_accuracy: 0.3837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e5860170d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training model\n",
    "img_rows, img_columns = 256, 256\n",
    "img_channels = 3\n",
    "batch_size = 16     # maybe use 64 or 128 so its faster\n",
    "nb_epochs = 5       # maybe use 3 so its faster\n",
    "# nb_classes = 10\n",
    "# nb_filters = 32\n",
    "# nb_pool = 2\n",
    "# nb_conv = 3\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(img_rows, img_columns, img_channels)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs = nb_epochs, verbose = 1, validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model above does not have a good generalization, but it will do for my purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From c:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/model1\\assets\n"
     ]
    }
   ],
   "source": [
    "# Saving trained model in both the formats SavedModel and HDF5\n",
    "model.save('saved_model/model1')\n",
    "model.save('model1_h5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test and y_test\n",
    "testing = []\n",
    "for category in CATEGORIES:\n",
    "    path = os.path.join(test_path, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img))\n",
    "        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "        testing.append([new_array, class_num])\n",
    "\n",
    "random.shuffle(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [features for features, label in testing]\n",
    "y_test = [label for features, label in testing]\n",
    "# for features, label in testing:\n",
    "#     X_test.append(features)\n",
    "#     y_test.append(label)\n",
    "# reshape for the input format expected by keras (256, 256, 3) - 3 channels\n",
    "X_test = np.array(X_test).reshape(-1, IMG_SIZE, IMG_SIZE, 3).astype('float32')\n",
    "# normalizing the pixel values\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "(1500, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "print(y_test[100])\n",
    "print(shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  3.58614182472229\n",
      "Test accuracy:  0.41466665267944336\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model performance on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose = 0 )\n",
    "print(\"Test Score: \", score[0])\n",
    "print(\"Test accuracy: \", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
